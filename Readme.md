# Readme
[开发日志](./markdown/开发日志)

创建十亿数据进行排序。最终实现高效查询

暂时实现所需内容
1. 生成测试数据
2. 将数据排序并保存
3. 查询数据

### 暂定目标
实现一个能增删查改并且附带索引的简易型数据库

### 遇到的问题
#### 1. 生成测试数据过慢
##### 思路:
单线程生成测试数据
生成一个数据，向文本写出一个数据。循环十亿次

##### 改良：
- 方式1：一个线程用于生产测试数据。另一个线程用于将数据写入文本
- 方式2：多个线程生产数据，多个线程从取出数据写入文本

#### 2. 将测试数据分块排序并保存
##### 思路：
从文本中读数据，将其排序。写入文本
由于内存过小，无法一次性排序完成，所以我们改变思路：
- 从文本中读取一定量数据（自己设置
- 对其进行排序
- 写入到文件中
##### 改良：
- 方式1
    - 读取数据后我们需要将其反序列化成`model.data`类型,我们将这一步拆分。使io一直在运行不被其他占用。
    - 读取到一定内存量时，我们对其进行排序。再将数据写出到不同的文件
    - 继续开始读取内存，直到将当前文件整个排序完成

#### 3. 外排序
#### 当前外排序思路
1. 开启多个`io`，开启`io`数量为`a`。
2. 获取一行数据`io`的数据。
3. `n`为当前读取到的行数。由于当前数据是经过内排序的。所以在同一个`io`中第`n`行小于或等于`n+1`行
4. 我们使用插入法找出最值(当前为最小值)。记录其下标`min`
5. 写出到文本。
6. 回到 ->2.
7. 当前`io`获取完毕则不对当前io进行任何操作。
8. 当所有`io`获取完毕，则将`io`关闭。如还需合并，则回到 ->1.
9. 最终将所有数据输出到一个指定文件中

使用插入法获取当前数组最小
##### 优化性能
计算机科学家吉姆·格雷的Sort Benchmark网站用不同的硬件、软件环境测试了实现方法不同的多种外排序算法的效率。效率较高的算法具有以下的特征：

- 并行计算
    - 用多个磁盘驱动器并行处理数据，可以加速顺序磁盘读写。[4]
    - 在计算机上使用多线程，可在多核心的计算机上得到优化。
    - 使用异步输入输出，可以同时排序和归并，同时读写。
    - 使用多台计算机用高速网络连接，分担计算任务。[5]
- 提高硬件速度
    - 增大内存，减小磁盘读写次数，减小归并次数。
    - 使用快速的外存设备，比如15000 RPM的硬盘或固态硬盘。
    - 使用性能更优良个各种设备，比如使用多核心CPU和延迟时间更短的内存。
- 提高软件速度
    - 对于某些特殊数据，在第一阶段的排序中使用基数排序。
    - 压缩输入输出文件和临时文件。
### 遇到的坑

#### []byte字节数组在某种情况下数值发生改变
最开始我以为是`unsafe.Pointer`的问题。直到我删除了那部分，并使用`[]byte`进行读取到内存中，将内存中的[]byte写入到新的文本。发现数据会发生变化。

曾经我们使用`unsafe.Pointer`将`[]byte`类型转换成`string`类型，之前出现问题的原因也是因为`[]byte`中发生变化。由于我们当时是使用`unsafe.Pointer`当前原理为，直接将`[]byte`中的值使用`string`去解析。所以当我们`[]byte`发生变化，`string`的值也会发生变化。由于我们现在使用`string()`将`[]byte`转换成字符串，当前操作会复制一份在内存中的值，并将其进行转换，所以当前操作会消耗更大的内存。

当前我们需要找出什么原因导致的`[]byte`数组中的值发生变化

##### 找到问题

原因是`bufio`
每次`ReadLine`的返回值都是缓冲区的切片，所以缓冲区发生改变时（在缓冲区读取下一片内容时会发生改变），我们的`[]byte`字节也会发生改变。
[br.ReadLine解析](./markdown/Bufio.md)

#### bytes.ByteIndex()
无视切片。直接从头遍历



### 学习内容
假如需要完成以上的内容，并且在性能上有一定的要求，我们就需要用到一些知识

#### io
#### 内存管理
#### []byte转string的最优方式

#### 字符串切割以及合并的替代方案
寻找以及理解，并且解决`string.Split`与`fmt.Sprintf`的效率问题以及内存占用问题。
> [高效截取字符串](https://juejin.im/post/6844903984243671048)
发现当前并不是我们想要的效果，我们从`string`的原理与`unsafe.Pointer`开始了解。看看有没有什么我们能替换的内容
##### 发现问题
由于 string是一个不可改变的字节。所以我们在切割的时候必定会导致从内存复制一份进行切割。
##### 解决方式
回顾我们的需求，我们可以使用`ReadLine()([]byte,bool,error)` 读取字节，对字节进行判断，由于我们只需要获取`data.Num`,所以我们可以通过遍历只截取第一个`,`前的数值将其转换成`int`类型，然后保留当前整个[]byte。当内存超出时，我们进行排序。最终直接写出 []byte。
相比于以往。从文件中读取 `[]byte` 转换成 `string` 在通过程序 切割数据变成 `[]string` 转换成data中各自需要的内容 经过排序后在 转换成 `string` 写出 在内部再转换成 `[]byte`保存到文件
当前操作为。从文件中读取 `[]byte` 获取特定值转换成 `int` 保留原`[]byte`，再通过程序对当前的`int`进行排序，最终把`[]byte`写出文件
我们减少了`string`的生成，减少了`gc`的压力，同时降低了cpu的操作

`BenchmarkProduceDataStrconv`与`BenchmarkProduceDataFmtSprinf`的不同点为
一个使用`strconv.Itoa(rand.Int()) + "," + getName() + "," + getSex() + "\n"`
一个使用`fmt.Sprintf("%d,%s,%s",rand.Int(),getName(),getSex())`
```shell
goos: linux
goarch: amd64
pkg: test
BenchmarkProduceDataStrconv-6     	1000000000	         0.108 ns/op	       0 B/op	       0 allocs/op
BenchmarkProduceDataFmtSprinf-6   	1000000000	         0.124 ns/op	       0 B/op	       0 allocs/op
PASS
ok  	test	2.552s
```
单次生成`100000`数据，内存使用:
```markdown
strconv.Itoa -> m.Alloc=442704 m.Sys=74269696   0.116s
fmt.Sprintf -> m.Alloc=4160384 m.Sys=74007552 0.139s
```
由此可以得出：使用`strconv.Itoa`转换int，并且使用`+`与其他字符串进行拼接的效率是较高的



#### 在什么时候用什么排序
#### 二分查找法
#### 硬盘索引如何实现
#### 知名数据库底层存储方式
#### 多线程优化理解
